{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as json\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenamos datasets del 2019 y 2020, con datos completos, y del 2021, con información incompleta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin = pd.read_csv(r\"C:\\Users\\Nicolás\\Documents\\Data Science\\Desafio Final\\Renzo\\Desafio_full.csv\",\n",
    "                          sep=\";\", encoding='IBM850', low_memory=False)\n",
    "data_origin = data_origin.drop(7, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021 = pd.read_csv(\n",
    "    r'C:\\Users\\Nicolás\\Documents\\Data Science\\Desafio Final\\Renzo\\PARA_PRODUCCION.csv', sep=',', encoding='IBM850')\n",
    "data_2021.columns = ['NUMERO CLIENTE', 'AÑO', 'Mes', 'Kilos']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_origin.columns:\n",
    "    if(i not in data_2021.columns):\n",
    "        data_2021[i] = np.zeros(len(data_2021))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = pd.concat([data_origin, data_2021])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formateamos los datos, obtenemos las devoluciones, filtramos los mercados que nos interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, to_floats, to_remove, to_remove_markets):\n",
    "        self.to_floats = to_floats\n",
    "        self.to_remove = to_remove\n",
    "        self.to_remove_markets = to_remove_markets\n",
    "\n",
    "    def to_float_with_extra_steps(self, val):\n",
    "        try:\n",
    "            val = val.replace(',', '.')\n",
    "            return float(val)\n",
    "        except:\n",
    "            try:\n",
    "                return float(val)\n",
    "            except:\n",
    "                return np.NaN\n",
    "\n",
    "    def returns(self, record):\n",
    "        if((record[\"Tipo orden\"] == \"CO\") & (record[\"Kilos\"] < 0)):\n",
    "            record[\"Devoluciones\"] = record['N° Factura']\n",
    "        else:\n",
    "            record[\"Devoluciones\"] = np.NaN\n",
    "        return record\n",
    "\n",
    "    def payment_condition(self, df):\n",
    "        keys = df['Condición de pago'].unique()\n",
    "        values = [30, 15, 45, 30, 60, 45, 90, 45, 30, 60, 0, 0, 7, 30, 75, 45, 60, 21, 60, 90, 110, 120,\n",
    "                  74, 105, 40, 70, 50, 37.5, 60, 75, 14, 40, 37.5, 105, 0, 15, 1, 75, 20, 80, 120, 30, 45, 15, 90]\n",
    "        replacement_dict = dict(zip(keys, values))\n",
    "        df['Condición de pago'] = df['Condición de pago'].replace(\n",
    "            replacement_dict)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,  X, y=None):\n",
    "        X = self.payment_condition(X)\n",
    "        df_dict = X.to_dict('records')\n",
    "        df_final = []\n",
    "        for i in enumerate(df_dict):\n",
    "            for j in self.to_floats:\n",
    "                df_dict[i[0]][j] = self.to_float_with_extra_steps(\n",
    "                    val=(i[1][j]))\n",
    "            df_dict[i[0]] = self.returns(record=i[1])\n",
    "            for h in self.to_remove:\n",
    "                if(df_dict[i[0]][h]):\n",
    "                    del df_dict[i[0]][h]\n",
    "            if(i[1][\"Mercado\"] not in self.to_remove_markets):\n",
    "                df_final.append(i[1])\n",
    "        return pd.DataFrame(df_final).sort_values(by=['Mes', 'AÑO'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos el cuatrimestre de cada registro, agrupamos y calculamos features adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quarters_and_grouping(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, agg_dict):\n",
    "        self.agg_dict = agg_dict\n",
    "\n",
    "    def month_converter(self, df_dict, years):\n",
    "        # Convierte meses a numeros continuos para el conjunto de años consecutivos\n",
    "        years.sort()\n",
    "        for i in enumerate(df_dict):\n",
    "            df_dict[i[0]][\"Mes\"] += (12 * years.index(i[1][\"AÑO\"]))\n",
    "        return df_dict\n",
    "\n",
    "    def feature_addition_pre(self, df):\n",
    "\n",
    "        \n",
    "\n",
    "        provdict = {}\n",
    "\n",
    "        df = df.drop([\"Moneda\", \"Pais\", \"Subrubro\"], axis=1)\n",
    "\n",
    "        cache_df_prov = df.loc[:, [\"NUMERO CLIENTE\", \"Provincia\", \"Kilos\"]]\n",
    "        cache_df_prov_ = cache_df_prov.groupby(by=[\"NUMERO CLIENTE\", \"Provincia\"]).agg({\n",
    "            \"Kilos\": \"sum\"}).reset_index()\n",
    "        \n",
    "        # Obtiene la Provincia con más Kilos vendidos para cada cliente, y features adicionales\n",
    "        for i in cache_df_prov_[\"NUMERO CLIENTE\"].unique():\n",
    "            cache = cache_df_prov_[cache_df_prov_[\"NUMERO CLIENTE\"] == i]\n",
    "            provincia = cache.loc[cache.Kilos.idxmax(), [\n",
    "                \"Provincia\"]].Provincia\n",
    "            provdict[i] = provincia\n",
    "\n",
    "        df[\"Provincia\"] = df[\"NUMERO CLIENTE\"].replace(provdict)\n",
    "        df[\"Kilos_Promedio\"] = df[\"Kilos\"]\n",
    "        df[\"Kilos_Maximo\"] = df[\"Kilos\"]\n",
    "        df[\"Kilos_Minimo\"] = df[\"Kilos\"]\n",
    "        df[\"Frecuencia\"] = df[\"Mes\"]\n",
    "        df[\"USD/Ton\"] = df.apply(lambda x: (x['USD TC Prom.Mes']/(x['Kilos']/1000)) if ((x['Kilos']\n",
    "                                                                                         > 100) & (x['USD TC Prom.Mes'] > 100)) else np.nan, axis=1)\n",
    "        return df\n",
    "\n",
    "    def quarters(self, df_list, years):\n",
    "        # Genera cuatrimestres con meses solapados (1 a 4, 2 a 5, etc). Las keys son los meses y los values arrays de cuatrimestres.     \n",
    "        dfnew = []\n",
    "        for i in df_list:\n",
    "            Qs = []\n",
    "            month = i[\"Mes\"]\n",
    "            # Genera listas de cuatrimestres con 0 o 1 en cada posición, dependiendo de si el mes pertenece al mismo.\n",
    "            for q in range(1, (12*len(years)) - 2):\n",
    "                if((q >= (month - 3)) & (q <= month)):\n",
    "                    Qs.append(1)\n",
    "                else:\n",
    "                    Qs.append(0)\n",
    "            for v in enumerate(Qs, 0):\n",
    "                if(v[1]):\n",
    "                    new = dict(i)\n",
    "                    quarter = v[0] + 1\n",
    "                    new.update({\"Cuatrimestre\": quarter})\n",
    "                    # Genera columnas con los meses de ese cuatrimestre. Sirve para calcular la target más adelante.\n",
    "                    new[\"Mes1\"] = 0\n",
    "                    new[\"Mes2\"] = 0\n",
    "                    new[\"Mes3\"] = 0\n",
    "                    new[\"Mes4\"] = 0\n",
    "                    quarter_position = i[\"Mes\"] - v[0]\n",
    "\n",
    "                    for m in range(1, 5):\n",
    "                        new[\"Mes\" + str(m)] = i[\"Mes\"] - (quarter_position - m)\n",
    "\n",
    "                    del new[\"Mes\"]\n",
    "                    dfnew.append(new)\n",
    "        return dfnew\n",
    "\n",
    "    def grouping(self, df):\n",
    "        agg = self.agg_dict\n",
    "        agg[\"Kilos_Promedio\"] = np.mean\n",
    "        agg[\"Kilos_Maximo\"] = 'max'\n",
    "        agg[\"Kilos_Minimo\"] = 'min'\n",
    "        agg[\"Frecuencia\"] = 'nunique'\n",
    "        agg[\"USD/Ton\"] = np.mean\n",
    "\n",
    "        for key in [\"Mes1\", \"Mes2\", \"Mes3\", \"Mes4\"]:\n",
    "            agg[key] = 'first'\n",
    "\n",
    "        df_g = df.groupby(\n",
    "            by=['NUMERO CLIENTE', 'Cuatrimestre']).agg(agg).reset_index()\n",
    "\n",
    "        df_g_ = df_g[df_g[\"Kilos\"] > 0]\n",
    "        return df_g_\n",
    "\n",
    "    def feature_addition_post(self, df):\n",
    "        df[\"Indice devoluciones\"] = (df['Devoluciones']/df['N° Factura'])\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        years = list(X[\"AÑO\"].unique())\n",
    "        df_list = X.to_dict('records')\n",
    "\n",
    "        data_months_converted = self.month_converter(\n",
    "            df_dict=df_list, years=years)\n",
    "        df = pd.DataFrame(data_months_converted)\n",
    "\n",
    "        data_f = self.feature_addition_pre(df=df)\n",
    "        df_list = data_f.to_dict('records')\n",
    "\n",
    "        data_q = self.quarters(df_list=df_list, years=years)\n",
    "\n",
    "        df_ = pd.DataFrame(data_q)\n",
    "        data_g = self.grouping(df=df_)\n",
    "\n",
    "        data_h = self.feature_addition_post(data_g)\n",
    "\n",
    "        return data_h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos la target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class target_definition(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def target_calculation(self, df_list):\n",
    "        target = []\n",
    "        for i in df_list:\n",
    "            sum = 0\n",
    "            for j in df_list:\n",
    "                if(i[\"NUMERO CLIENTE\"] == j[\"NUMERO CLIENTE\"]):\n",
    "                    if(np.less(i[\"Mes4\"], j[\"Mes1\"])):\n",
    "                        if((j[\"Mes4\"] - i[\"Mes4\"]) <= 12):\n",
    "                            sum += j[\"Kilos\"]\n",
    "            target.append(int(sum <= 0))\n",
    "        data_target = pd.DataFrame(df_list)\n",
    "        data_target[\"Target\"] = target\n",
    "        return data_target\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data_list = X.to_dict('records')\n",
    "        data_target = self.target_calculation(df_list=data_list)\n",
    "        return data_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos columnas utilizadas para calcular la target, descartamos los datos del 2021, filtramos outliers y generamos dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Postprocessing(BaseEstimator, TransformerMixin):\n",
    "    def post_processing(self, df):\n",
    "        last_month = df[\"Mes4\"].values.max()\n",
    "        df_ = df[df[\"Mes4\"] < (last_month - 12)]\n",
    "        df_ = df_.drop([\"AÑO\", \"Mes1\", \"Mes2\", \"Mes3\",\n",
    "                       \"Mes4\", \"Mercado\"], axis=1)\n",
    "        df_ = df_[df_[\"USD/Ton\"] < 5000]\n",
    "        prov_dummies = pd.get_dummies(df_[\"Provincia\"])\n",
    "        df_ = df_.drop(\"Provincia\", axis=1)\n",
    "\n",
    "        rubro_dummies = pd.get_dummies(df_[\"Rubro\"])\n",
    "        df_ = df_.drop(\"Rubro\", axis=1)\n",
    "\n",
    "        df_f = df_.join(prov_dummies)\n",
    "        df_f = df_f.join(rubro_dummies)\n",
    "        df_f.dropna(how='any', inplace=True, axis=0)\n",
    "        return df_f\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        data_final = self.post_processing(df=X)\n",
    "        return data_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argumentos para las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_floats = ['NUMERO CLIENTE', 'Línea', 'Cantidad', 'Precio Unitario',\n",
    "             'Tipo cbio. Prom.Mes', 'Kilos', 'Pesos', 'm2', 'USD TC Prom.Mes']\n",
    "to_remove = [\"Orden\", \"Remito\", \"Orden Orig.\", \"Tipo orden\",\n",
    "             \"Período\", \"Cartón\", \"Precio total\", \"m2\", \"Pesos\", \"Línea\", \"TM\"]\n",
    "to_remove_markets = [\"MEG\", \"MIG\"]\n",
    "agg_dict = {'N° Factura': 'nunique', 'SKU': 'nunique', 'Cantidad': np.sum, 'Precio Unitario': np.mean, 'Mercado': 'first', 'Tipo cbio. Prom.Mes': np.mean, 'Kilos': np.sum,\n",
    "            'USD TC Prom.Mes': np.sum, 'Rubro': 'first',\n",
    "            'Provincia': 'first', 'Condición de pago': 'max', 'Devoluciones': 'nunique', \"AÑO\": 'max'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos instancias de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Preprocessing(to_floats=to_floats, to_remove=to_remove,\n",
    "                    to_remove_markets=to_remove_markets)\n",
    "\n",
    "data_g = Quarters_and_grouping(agg_dict=agg_dict)\n",
    "\n",
    "data_target = target_definition()\n",
    "\n",
    "data_final = Postprocessing()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos un pipeline con todas las etapas para el entrenamiento del modelo predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_train_test = [('Preprocessing', pre), ('Quarters and grouping', data_g),\n",
    "                    ('target_calculation', data_target), ('Postprocessing', data_final)]\n",
    "pipe = Pipeline(steps_train_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed_model = pipe.fit_transform(data_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos otro, sin cálculo de la target, para los datos que procesará el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_api = [('Preprocessing', pre), ('Quarters and grouping',\n",
    "                                      data_g), ('Postprocessing', data_final)]\n",
    "pipe_api = Pipeline(steps_api)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_api = pipe_api.fit_transform(data_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed_model.to_csv(\n",
    "    r\"C:\\Users\\Nicolás\\Documents\\Data Science\\Desafio Final\\Renzo\\data_final.csv\", encoding=\"UTF-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
